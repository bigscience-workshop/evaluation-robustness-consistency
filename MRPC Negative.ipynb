{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import logging\n",
    "import transformers\n",
    "from bert_score import score\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Openinng outputs/T0_3B_generation_t1_rp1.5_lp1_ml30_nb10_10/mrpc-negative.json\n",
      "Accuracy 0.6151960784313726\n",
      "Consistency 0.9558823529411765\n"
     ]
    }
   ],
   "source": [
    "data_path ='outputs'\n",
    "file_name = 'T0_3B_generation_t1_rp1.5_lp1_ml30_nb10_10'\n",
    "file_path = os.path.join(data_path,file_name,'mrpc-negative.json')\n",
    "print('Openinng',file_path)\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path,'r') as file:\n",
    "        file = json.load(file)\n",
    "    print('Accuracy',file['accuracy'])\n",
    "    print('Consistency',file['consistency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study of the uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.32787883281707764, 0.6721211075782776] [0.3509794771671295, 0.6490204930305481]\n",
      "[0.4285570979118347, 0.5714429616928101] [0.4165370464324951, 0.5834629535675049]\n",
      "[0.6715832948684692, 0.3284166753292084] [0.6358197927474976, 0.36418023705482483]\n",
      "[0.5882970094680786, 0.4117029905319214] [0.5672550201416016, 0.43274497985839844]\n",
      "[0.5676711797714233, 0.4323287606239319] [0.5458579063415527, 0.45414209365844727]\n",
      "[0.6119723320007324, 0.38802772760391235] [0.5975478291511536, 0.4024522006511688]\n",
      "[0.5634849071502686, 0.43651506304740906] [0.5588682889938354, 0.44113171100616455]\n",
      "[0.5393760800361633, 0.46062391996383667] [0.5389453172683716, 0.4610547125339508]\n",
      "[0.6748654842376709, 0.3251345753669739] [0.681418776512146, 0.3185811936855316]\n",
      "[0.5086709260940552, 0.4913291335105896] [0.4899972379207611, 0.5100026726722717]\n",
      "[0.43567830324172974, 0.5643216967582703] [0.40939006209373474, 0.5906099677085876]\n",
      "[0.22900334000587463, 0.7709965705871582] [0.2173764556646347, 0.7826235294342041]\n",
      "[0.7572043538093567, 0.2427956461906433] [0.7324946522712708, 0.26750531792640686]\n",
      "[0.4119524359703064, 0.5880475044250488] [0.4144965410232544, 0.5855034589767456]\n",
      "[0.49353256821632385, 0.5064674615859985] [0.46585068106651306, 0.5341493487358093]\n",
      "[0.5242766737937927, 0.4757232964038849] [0.4886989891529083, 0.5113010406494141]\n",
      "[0.3810117244720459, 0.6189882755279541] [0.37589797377586365, 0.6241020560264587]\n",
      "[0.6841733455657959, 0.3158266246318817] [0.6820569634437561, 0.3179430663585663]\n",
      "[0.5658189058303833, 0.4341810345649719] [0.5702584385871887, 0.42974159121513367]\n",
      "[0.7721875905990601, 0.22781240940093994] [0.7729312777519226, 0.2270687371492386]\n",
      "[0.5146904587745667, 0.48530954122543335] [0.4815952777862549, 0.5184047818183899]\n",
      "[0.6401227712631226, 0.35987716913223267] [0.643767237663269, 0.35623273253440857]\n",
      "[0.406514048576355, 0.593485951423645] [0.41198208928108215, 0.588018000125885]\n",
      "[0.24138984084129333, 0.758610188961029] [0.2126832902431488, 0.7873167395591736]\n",
      "[0.5275328755378723, 0.47246718406677246] [0.5321478247642517, 0.4678521752357483]\n",
      "[0.582898736000061, 0.41710129380226135] [0.577203094959259, 0.42279693484306335]\n",
      "[0.46232128143310547, 0.5376786589622498] [0.44278520345687866, 0.5572147965431213]\n",
      "[0.23392710089683533, 0.7660729289054871] [0.25011560320854187, 0.7498843669891357]\n",
      "[0.34592217206954956, 0.6540778279304504] [0.34663113951683044, 0.6533688306808472]\n",
      "[0.45795756578445435, 0.5420423746109009] [0.42205512523651123, 0.5779448747634888]\n",
      "[0.5445407629013062, 0.45545923709869385] [0.5056722164154053, 0.4943277835845947]\n",
      "[0.22283457219600677, 0.7771654725074768] [0.21269254386425018, 0.7873074412345886]\n",
      "[0.41439053416252136, 0.585609495639801] [0.3704886734485626, 0.629511296749115]\n",
      "[0.5878132581710815, 0.41218674182891846] [0.5735874176025391, 0.42641252279281616]\n",
      "[0.436300665140152, 0.5636993050575256] [0.4340096116065979, 0.5659904479980469]\n",
      "[0.2627568542957306, 0.7372431755065918] [0.2712026834487915, 0.7287973165512085]\n",
      "[0.4691924452781677, 0.5308074951171875] [0.43959885835647583, 0.5604011416435242]\n",
      "[0.5484023690223694, 0.4515976309776306] [0.5394618511199951, 0.4605381190776825]\n",
      "[0.6247264742851257, 0.3752734959125519] [0.6223920583724976, 0.37760791182518005]\n",
      "[0.17470048367977142, 0.8252995014190674] [0.19180326163768768, 0.8081967830657959]\n",
      "[0.6272629499435425, 0.3727370798587799] [0.6052495837211609, 0.3947504162788391]\n",
      "[0.5041264891624451, 0.4958735704421997] [0.48042723536491394, 0.5195727348327637]\n",
      "[0.27225956320762634, 0.727740466594696] [0.257167786359787, 0.7428321838378906]\n",
      "[0.4675501883029938, 0.5324498414993286] [0.444789856672287, 0.5552100539207458]\n",
      "[0.6753465533256531, 0.3246534466743469] [0.6666629314422607, 0.33333703875541687]\n",
      "[0.5643789172172546, 0.43562108278274536] [0.5455055832862854, 0.4544943571090698]\n",
      "[0.43199601769447327, 0.5680040121078491] [0.4043181538581848, 0.5956817865371704]\n",
      "[0.5808661580085754, 0.4191338121891022] [0.5741326808929443, 0.4258672893047333]\n",
      "[0.2946650981903076, 0.7053349018096924] [0.2861934006214142, 0.7138065695762634]\n",
      "[0.5379309058189392, 0.4620690941810608] [0.5493441224098206, 0.45065590739250183]\n",
      "[0.5237438678741455, 0.4762561023235321] [0.5044816732406616, 0.4955183267593384]\n"
     ]
    }
   ],
   "source": [
    "for index, (pos,neg) in enumerate(zip(file['std answer'],file['neg answer'])):\n",
    "    print(pos,neg)\n",
    "    if index == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson\n",
      "Pos (0.9999999999999999, 0.0)\n",
      "Neg (1.0, 0.0)\n",
      "Pos/Neg (-0.999999999999956, 0.0)\n",
      "Neg/Pos (-0.999999999999956, 0.0)\n"
     ]
    }
   ],
   "source": [
    "print('Pearson')\n",
    "x = [i[0] for i in file['std answer']]\n",
    "y = [i[0] for i in file['std answer']]\n",
    "print('Pos',scipy.stats.pearsonr(x, y))\n",
    "\n",
    "x = [i[1] for i in file['std answer']]\n",
    "y = [i[1] for i in file['std answer']]\n",
    "print('Neg',scipy.stats.pearsonr(x, y))\n",
    "\n",
    "x = [i[0] for i in file['std answer']]\n",
    "y = [i[1] for i in file['std answer']]\n",
    "print('Pos/Neg',scipy.stats.pearsonr(x, y))\n",
    "\n",
    "x = [i[1] for i in file['std answer']]\n",
    "y = [i[0] for i in file['std answer']]\n",
    "print('Neg/Pos',scipy.stats.pearsonr(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall\n",
      "Pos KendalltauResult(correlation=0.9999999999999998, pvalue=0.0)\n",
      "Neg KendalltauResult(correlation=0.9999999999999998, pvalue=0.0)\n",
      "Pos/Neg KendalltauResult(correlation=-0.9999999999999998, pvalue=0.0)\n",
      "Neg/Pos KendalltauResult(correlation=-0.9999999999999998, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "print('Kendall')\n",
    "x = [i[0] for i in file['std answer']]\n",
    "y = [i[0] for i in file['std answer']]\n",
    "print('Pos',scipy.stats.kendalltau(x, y))\n",
    "\n",
    "x = [i[1] for i in file['std answer']]\n",
    "y = [i[1] for i in file['std answer']]\n",
    "print('Neg',scipy.stats.kendalltau(x, y))\n",
    "\n",
    "x = [i[0] for i in file['std answer']]\n",
    "y = [i[1] for i in file['std answer']]\n",
    "print('Pos/Neg',scipy.stats.kendalltau(x, y))\n",
    "\n",
    "x = [i[1] for i in file['std answer']]\n",
    "y = [i[0] for i in file['std answer']]\n",
    "print('Neg/Pos',scipy.stats.kendalltau(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmna\n",
      "Pos SpearmanrResult(correlation=1.0, pvalue=0.0)\n",
      "Neg SpearmanrResult(correlation=1.0, pvalue=0.0)\n",
      "Pos/Neg SpearmanrResult(correlation=-1.0, pvalue=0.0)\n",
      "Neg/Pos SpearmanrResult(correlation=-1.0, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "print('Spearmna')\n",
    "x = [i[0] for i in file['std answer']]\n",
    "y = [i[0] for i in file['std answer']]\n",
    "print('Pos',scipy.stats.spearmanr(x, y))\n",
    "\n",
    "x = [i[1] for i in file['std answer']]\n",
    "y = [i[1] for i in file['std answer']]\n",
    "print('Neg',scipy.stats.spearmanr(x, y))\n",
    "\n",
    "x = [i[0] for i in file['std answer']]\n",
    "y = [i[1] for i in file['std answer']]\n",
    "print('Pos/Neg',scipy.stats.spearmanr(x, y))\n",
    "\n",
    "x = [i[1] for i in file['std answer']]\n",
    "y = [i[0] for i in file['std answer']]\n",
    "print('Neg/Pos',scipy.stats.spearmanr(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inconsistency sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtained consistency 0.9558823529411765\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "inconsistent_index = []\n",
    "assert len(file['std answer']) == len(file['neg answer'])\n",
    "for index, (pos,neg) in enumerate(zip(file['std answer'],file['neg answer'])):\n",
    "    if pos.index(max(pos)) == neg.index(max(neg)):\n",
    "        count +=1 \n",
    "    else :\n",
    "        inconsistent_index.append(index)\n",
    "print('Obtained consistency', count/len(file['std answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neg prompt\n",
      "Sentence 1: The results appear in the January issue of Cancer , an American Cancer Society journal , being published online today .\n",
      "Sentence 2: The results appear in the January issue of Cancer , an American Cancer Society ( news - web sites ) journal , being published online Monday .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: The results appear in the January issue of Cancer , an American Cancer Society journal , being published online today .\n",
      "Sentence 2: The results appear in the January issue of Cancer , an American Cancer Society ( news - web sites ) journal , being published online Monday .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Unable to find a home for him , a judge told mental health authorities they needed to find supervised housing and treatment for DeVries somewhere in California .\n",
      "Sentence 2: The judge had told the state Department of Mental Health to find supervised housing and treatment for DeVries somewhere in California .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Unable to find a home for him , a judge told mental health authorities they needed to find supervised housing and treatment for DeVries somewhere in California .\n",
      "Sentence 2: The judge had told the state Department of Mental Health to find supervised housing and treatment for DeVries somewhere in California .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Friday , Stanford ( 47-15 ) blanked the Gamecocks 8-0 .\n",
      "Sentence 2: Stanford ( 46-15 ) has a team full of such players this season .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Friday , Stanford ( 47-15 ) blanked the Gamecocks 8-0 .\n",
      "Sentence 2: Stanford ( 46-15 ) has a team full of such players this season .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Authorities had no evidence to suggest the two incidents were connected .\n",
      "Sentence 2: There was no immediate evidence that the two incidents were connected , police said .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Authorities had no evidence to suggest the two incidents were connected .\n",
      "Sentence 2: There was no immediate evidence that the two incidents were connected , police said .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: The charges allege that he was part of the conspiracy to kill and kidnap persons in a foreign country .\n",
      "Sentence 2: The government now charges that Sattar conspired with Rahman to kill and kidnap individuals in foreign countries .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: The charges allege that he was part of the conspiracy to kill and kidnap persons in a foreign country .\n",
      "Sentence 2: The government now charges that Sattar conspired with Rahman to kill and kidnap individuals in foreign countries .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: The agency charged that one WD Energy worker discussed false reporting with traders at two other energy companies .\n",
      "Sentence 2: The agency found further that a WD Energy employee discussed false reporting with traders at two other energy companies , which the CFTC didn 't identify .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 0\n",
      "Pos prompt\n",
      "Sentence 1: The agency charged that one WD Energy worker discussed false reporting with traders at two other energy companies .\n",
      "Sentence 2: The agency found further that a WD Energy employee discussed false reporting with traders at two other energy companies , which the CFTC didn 't identify .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 1\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: All patients developed some or all of the symptoms of E. coli food poisoning : bloody diarrhea , vomiting , abdominal cramping and nausea .\n",
      "Sentence 2: Symptoms of the E. coli infection include bloody diarrhea , nausea , vomiting and abdominal cramping .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: All patients developed some or all of the symptoms of E. coli food poisoning : bloody diarrhea , vomiting , abdominal cramping and nausea .\n",
      "Sentence 2: Symptoms of the E. coli infection include bloody diarrhea , nausea , vomiting and abdominal cramping .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: He said his hatred for such people grew from these discussions and had helped convince him violence was the answer .\n",
      "Sentence 2: His hatred for these people had germinated from these discussions and helped cement his belief that violence was the panacea .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: He said his hatred for such people grew from these discussions and had helped convince him violence was the answer .\n",
      "Sentence 2: His hatred for these people had germinated from these discussions and helped cement his belief that violence was the panacea .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Friday 's report raised new worries that a weak job market could shackle the budding economic recovery despite a slight improvement in the overall unemployment rate .\n",
      "Sentence 2: U.S. companies slashed payrolls for a seventh straight month in August , raising new worries that a weak jobs market could shackle the budding economic recovery .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Friday 's report raised new worries that a weak job market could shackle the budding economic recovery despite a slight improvement in the overall unemployment rate .\n",
      "Sentence 2: U.S. companies slashed payrolls for a seventh straight month in August , raising new worries that a weak jobs market could shackle the budding economic recovery .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: BREAST cancer cases in the UK have hit an all-time high with more than 40,000 women diagnosed with the disease each year , Cancer Re-search UK revealed yesterday .\n",
      "Sentence 2: Cases of breast cancer in Britain have reached a record high , with the number of women diagnosed with the disease passing the 40,000 mark for the first time .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: BREAST cancer cases in the UK have hit an all-time high with more than 40,000 women diagnosed with the disease each year , Cancer Re-search UK revealed yesterday .\n",
      "Sentence 2: Cases of breast cancer in Britain have reached a record high , with the number of women diagnosed with the disease passing the 40,000 mark for the first time .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Freddie also said Leland C. Brendsel will retire as chairman and chief executive and resign from the board .\n",
      "Sentence 2: He replaces Leland Brendsel , 61 , who retired as chairman and chief executive .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Freddie also said Leland C. Brendsel will retire as chairman and chief executive and resign from the board .\n",
      "Sentence 2: He replaces Leland Brendsel , 61 , who retired as chairman and chief executive .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Drax faced a financial crisis late last year after it lost its most lucrative sales contract , held with insolvent utility TXU Europe .\n",
      "Sentence 2: Drax ’ s troubles began late last year when it lost its most lucrative sales contract , with the insolvent utility TXU Europe .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Drax faced a financial crisis late last year after it lost its most lucrative sales contract , held with insolvent utility TXU Europe .\n",
      "Sentence 2: Drax ’ s troubles began late last year when it lost its most lucrative sales contract , with the insolvent utility TXU Europe .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Franklin County Judge-Executive Teresa Barton said a firefighter was struck by lightning and was taken to the Frankfort Regional Medical Center .\n",
      "Sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Franklin County Judge-Executive Teresa Barton said a firefighter was struck by lightning and was taken to the Frankfort Regional Medical Center .\n",
      "Sentence 2: A county firefighter , was struck by lightning and was in stable condition at Frankfort Regional Medical Center .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: It also offers a built-in NAND flash boot loader so that high-density NAND flash memory can be used without having to install an additional support chip .\n",
      "Sentence 2: The S3C2440 has a built-in NAND flash boot loader , for example , so that high-density NAND flash memory can be installed without an additional support chip .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: It also offers a built-in NAND flash boot loader so that high-density NAND flash memory can be used without having to install an additional support chip .\n",
      "Sentence 2: The S3C2440 has a built-in NAND flash boot loader , for example , so that high-density NAND flash memory can be installed without an additional support chip .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: My decision today is not based on any one event . \"\n",
      "Sentence 2: Governor Rowland said his decision was \" not based on any one event . \"\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 0\n",
      "Pos prompt\n",
      "Sentence 1: My decision today is not based on any one event . \"\n",
      "Sentence 2: Governor Rowland said his decision was \" not based on any one event . \"\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 1\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Officials are also meeting with the International Organization for Epizootics ( OIE ) , which establishes animal-health standards for the world .\n",
      "Sentence 2: Canadian officials were also expected to meet yesterday with the International Organization for Epizootics ( OIE ) , which establishes animal-health standards for the world .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Officials are also meeting with the International Organization for Epizootics ( OIE ) , which establishes animal-health standards for the world .\n",
      "Sentence 2: Canadian officials were also expected to meet yesterday with the International Organization for Epizootics ( OIE ) , which establishes animal-health standards for the world .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: It 's happened five times in the last 11 years : A disaster puts this Southwestern town in the headlines during the summer tourist season .\n",
      "Sentence 2: It 's happened five times in the last decade : A disaster puts this tourist town in the headlines during summer , its busiest season .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: It 's happened five times in the last 11 years : A disaster puts this Southwestern town in the headlines during the summer tourist season .\n",
      "Sentence 2: It 's happened five times in the last decade : A disaster puts this tourist town in the headlines during summer , its busiest season .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n",
      "Neg prompt\n",
      "Sentence 1: Their contract will expire at 12 : 01 a.m. Wednesday instead of 12 : 01 a.m. Sunday , said Rian Wathen , organizing director for United Food and Commercial Workers Local 700 .\n",
      "Sentence 2: \" It has outraged the membership , \" said Rian Wathen , organizing director of United Food and Commercial Workers Local 700 .\n",
      "Do Sentence 1 and Sentence 2 express a different meaning? Yes or No?\n",
      "Answer 1\n",
      "Pos prompt\n",
      "Sentence 1: Their contract will expire at 12 : 01 a.m. Wednesday instead of 12 : 01 a.m. Sunday , said Rian Wathen , organizing director for United Food and Commercial Workers Local 700 .\n",
      "Sentence 2: \" It has outraged the membership , \" said Rian Wathen , organizing director of United Food and Commercial Workers Local 700 .\n",
      "Do Sentence 1 and Sentence 2 convey the same meaning? Yes or No?\n",
      "Answer 0\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for index_ in inconsistent_index:\n",
    "    print('Neg prompt')\n",
    "    print(file['neg prompt'][index_])\n",
    "    print('Answer', file['neg answer'][index_].index(max(file['neg answer'][index_])) )\n",
    "    print('Pos prompt')\n",
    "    print(file['std prompt'][index_])\n",
    "    print('Answer', file['std answer'][index_].index(max(file['std answer'][index_])) )\n",
    "    print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
